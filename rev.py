import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import time
import re
import nltk
from nltk.corpus import stopwords
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Set page configuration
st.set_page_config(
    page_title="Mealytics :Mealytics: AI-Powered Dining Intelligence",
    page_icon="üçΩÔ∏è",
    layout="wide"
)

# Custom CSS for better appearance
st.markdown("""
<style>
    .main {
        padding: 1rem 1rem;
    }
    .stProgress > div > div > div > div {
        background-color: #4CAF50;
    }
    .sentiment-positive {
        padding: 1.5rem;
        border-radius: 0.5rem;
        background-color: #E8F5E9;
        border-left: 6px solid #4CAF50;
        color: black !important;
    }
    .sentiment-negative {
        padding: 1.5rem;
        border-radius: 0.5rem;
        background-color: #FFEBEE;
        border-left: 6px solid #F44336;
        color: black !important;
    }
    .highlight {
        background-color: #F5F5F5;
        padding: 1rem;
        border-radius: 0.5rem;
        color: black !important;
    }
    /* Ensure all text in the report is black */
    .sentiment-positive p, .sentiment-negative p, .sentiment-positive h4, .sentiment-negative h4,
    .sentiment-positive span, .sentiment-negative span {
        color: black !important;
    }
    /* Make sure highlighted words remain clearly visible */
    span[style*="background-color: #E8F5E9"] {
        color: black !important;
    }
    span[style*="background-color: #FFEBEE"] {
        color: black !important;
    }
</style>
""", unsafe_allow_html=True)

# App title and description
st.title("üçΩÔ∏è Restaurant Review Sentiment Analysis")
st.markdown("""
This application uses an advanced BERT model to classify restaurant reviews as positive or negative.
The model is pre-trained on millions of examples and fine-tuned for sentiment analysis, providing
high accuracy even with complex language patterns.
""")

# Initialize session state variables
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'batch_results' not in st.session_state:
    st.session_state.batch_results = None
if 'tokenizer' not in st.session_state:
    st.session_state.tokenizer = None
if 'model' not in st.session_state:
    st.session_state.model = None

# Sidebar navigation
st.sidebar.title("Navigation")
pages = ["Single Review Analysis", "Batch Analysis", "Model Performance", "Insights"]
selection = st.sidebar.radio("Choose a section", pages)

# Load pre-trained model (with caching to avoid reloading)
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
    model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
    return tokenizer, model

# Function to predict sentiment
def predict_sentiment(text, tokenizer, model):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
    return probs.numpy()[0]

# Function to get sample data
def get_sample_data():
    data = pd.DataFrame({
        'Review': [
            "The food was absolutely delicious and the service was outstanding. I would highly recommend this restaurant to anyone looking for a great dining experience.",
            "Terrible experience. The food was cold and the staff was rude. We waited over an hour for our meal and when it finally arrived, it was completely wrong.",
            "I love this restaurant! The atmosphere is cozy and welcoming, the menu is diverse, and the prices are reasonable. Will definitely come back again.",
            "Average food, nothing special but not bad either. The service was prompt but the waiter seemed disinterested. Probably won't return.",
            "The ambiance was nice but the food was overpriced for what you get. I expected more flavor and larger portions for the price point.",
            "Great value for money, generous portions and tasty food. The chef came out to greet us which was a nice personal touch.",
            "Waited over an hour for our food. When we asked about the delay, the server was dismissive. Completely unacceptable for a Tuesday night when the restaurant wasn't even busy.",
            "The chef's special was amazing, truly a culinary delight! The fusion of flavors was unexpected and delightful. The sommelier provided excellent wine pairings.",
            "Not worth the hype. Mediocre food and slow service. The place was crowded and noisy, making it difficult to have a conversation.",
            "Excellent cuisine and friendly staff. Highly recommended! The pasta was freshly made and the sauce was clearly prepared with high-quality ingredients."
        ],
        'Sentiment': [1, 0, 1, 0, 0, 1, 0, 1, 0, 1]
    })
    return data

# Function to process text for highlighting
def highlight_sentiment_words(text):
    positive_words = ['delicious', 'outstanding', 'love', 'great', 'excellent', 'recommend', 'amazing', 'friendly', 
                     'best', 'wonderful', 'tasty', 'perfect', 'favorite', 'fresh', 'good', 'impressed', 'enjoy']
    
    negative_words = ['terrible', 'cold', 'rude', 'wrong', 'average', 'disinterested', 'overpriced', 'waited', 
                     'slow', 'mediocre', 'disappointing', 'bad', 'poor', 'awful', 'worst', 'unacceptable']
    
    words = text.lower().split()
    highlighted_text = text
    
    for word in positive_words:
        pattern = re.compile(re.escape(word), re.IGNORECASE)
        highlighted_text = pattern.sub(f'<span style="background-color: #E8F5E9; padding: 0px 3px; border-radius: 3px; color: black;">{word}</span>', highlighted_text)
    
    for word in negative_words:
        pattern = re.compile(re.escape(word), re.IGNORECASE)
        highlighted_text = pattern.sub(f'<span style="background-color: #FFEBEE; padding: 0px 3px; border-radius: 3px; color: black;">{word}</span>', highlighted_text)
    
    return highlighted_text

# Load model when app starts
if not st.session_state.model_loaded:
    with st.spinner("Loading sentiment analysis model... (this may take a moment)"):
        st.session_state.tokenizer, st.session_state.model = load_model()
        st.session_state.model_loaded = True

# Single Review Analysis page
if selection == "Single Review Analysis":
    st.header("üìù Analyze a Restaurant Review")
    
    # User input for prediction
    user_input = st.text_area("Enter a restaurant review:", height=150)
    
    # Example reviews dropdown
    with st.expander("Or choose from example reviews"):
        example_reviews = [
            "The food was incredible and the staff was very attentive. The ambiance was perfect for our anniversary dinner.",
            "Worst dining experience ever. The food was bland, overpriced, and the service was painfully slow.",
            "Decent food but the service was a bit slow. The restaurant has a nice atmosphere though.",
            "Great atmosphere and delicious cocktails, but slightly overpriced food with small portions."
        ]
        selected_example = st.selectbox("Select an example review", example_reviews)
        if st.button("Use this example"):
            user_input = selected_example
    
    # Analyze button
    col1, col2 = st.columns([1, 3])
    with col1:
        analyze_button = st.button("Analyze Sentiment", type="primary")
    
    # Make prediction
    if analyze_button and user_input:
        with st.spinner("Analyzing sentiment..."):
            # Get prediction
            probs = predict_sentiment(user_input, st.session_state.tokenizer, st.session_state.model)
            sentiment = "Positive" if probs[1] >= 0.5 else "Negative"
            confidence = probs[1] if sentiment == "Positive" else probs[0]
            
            # Display result
            st.markdown("### Analysis Result")
            
            # Highlight the review text
            highlighted_text = highlight_sentiment_words(user_input)
            
            # Display with custom styling
            if sentiment == "Positive":
                st.markdown(f"""
                <div class="sentiment-positive">
                    <h4>üòÉ Positive Sentiment</h4>
                    <p>Confidence: {confidence*100:.1f}%</p>
                    <p>"{highlighted_text}"</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="sentiment-negative">
                    <h4>üòû Negative Sentiment</h4>
                    <p>Confidence: {confidence*100:.1f}%</p>
                    <p>"{highlighted_text}"</p>
                </div>
                """, unsafe_allow_html=True)
            
            # Visual representation of confidence
            st.markdown("### Confidence Distribution")
            fig, ax = plt.subplots(figsize=(10, 3))
            bars = ax.barh(['Negative', 'Positive'], [probs[0], probs[1]], color=['#ff9999', '#99ff99'])
            ax.set_xlim(0, 1)
            ax.set_xlabel('Probability')
            ax.set_title('Sentiment Probability Distribution')
            for i, bar in enumerate(bars):
                ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f"{probs[i]:.2%}", va='center')
            st.pyplot(fig)
            
            # Explanation
            st.markdown("### Understanding the Analysis")
            st.info("""
            The model analyzes the review by processing the entire text and context, not just individual words. 
            However, certain key words and phrases often strongly influence sentiment classification.
            
            In the highlighted text above:
            - üü¢ Green highlights indicate words commonly associated with positive sentiment
            - üî¥ Red highlights indicate words commonly associated with negative sentiment
            
            The model goes beyond simple word counting and considers:
            - Word context and position
            - Negations (like "not good")
            - Sentence structure
            - Comparative language
            """)

# Batch Analysis page
elif selection == "Batch Analysis":
    st.header("üìä Batch Analysis of Reviews")
    
    upload_option = st.radio(
        "Choose data source:",
        ("Upload CSV file", "Use sample data")
    )
    
    data = None
    
    if upload_option == "Upload CSV file":
        st.info("Upload a CSV file with a column named 'Review' containing the reviews to analyze.")
        uploaded_file = st.file_uploader("Choose a CSV file", type="csv")
        
        if uploaded_file is not None:
            try:
                data = pd.read_csv(uploaded_file)
                if 'Review' not in data.columns:
                    st.error("The CSV file must contain a column named 'Review'")
                    data = None
            except Exception as e:
                st.error(f"Error reading the file: {e}")
                data = None
    else:
        data = get_sample_data()
        st.write("Sample Data Preview:")
        st.write(data.head())
    
    if data is not None:
        if st.button("Run Batch Analysis", type="primary"):
            with st.spinner("Analyzing reviews... This may take a while for large datasets."):
                progress_bar = st.progress(0)
                
                results = []
                total_reviews = len(data)
                
                for i, review in enumerate(data['Review']):
                    if review is not None and isinstance(review, str):
                        probs = predict_sentiment(review, st.session_state.tokenizer, st.session_state.model)
                        sentiment = "Positive" if probs[1] >= 0.5 else "Negative"
                        confidence = max(probs)
                        results.append({
                            'Review': review,
                            'Predicted_Sentiment': sentiment,
                            'Confidence': confidence,
                            'Positive_Probability': probs[1],
                            'Negative_Probability': probs[0]
                        })
                    
                    # Update progress bar
                    progress = min(1.0, (i + 1) / total_reviews)
                    progress_bar.progress(progress)
                
                # Create results DataFrame
                results_df = pd.DataFrame(results)
                
                # If original data had a Sentiment column, compare predictions
                if 'Sentiment' in data.columns:
                    # Map numeric to text for comparison
                    sentiment_map = {0: "Negative", 1: "Positive"}
                    true_sentiments = data['Sentiment'].map(sentiment_map)
                    
                    # Add True Sentiment column
                    results_df['True_Sentiment'] = true_sentiments.reset_index(drop=True)
                    
                    # Calculate accuracy
                    accuracy = (results_df['Predicted_Sentiment'] == results_df['True_Sentiment']).mean()
                    st.success(f"Analysis completed with an accuracy of {accuracy:.2%}")
                else:
                    st.success("Analysis completed!")
                
                # Store results in session state
                st.session_state.batch_results = results_df
                
                # Display results
                st.subheader("Analysis Results")
                st.dataframe(results_df)
                
                # Download button for results
                csv = results_df.to_csv(index=False)
                st.download_button(
                    label="Download results as CSV",
                    data=csv,
                    file_name="sentiment_analysis_results.csv",
                    mime="text/csv",
                )
                
                # Display summary
                st.subheader("Summary")
                sentiment_counts = results_df['Predicted_Sentiment'].value_counts()
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Sentiment distribution pie chart
                    fig, ax = plt.subplots(figsize=(8, 8))
                    colors = ['#ff9999', '#99ff99']
                    sentiment_counts.plot.pie(autopct='%1.1f%%', ax=ax, colors=colors)
                    ax.set_ylabel('')
                    ax.set_title('Sentiment Distribution')
                    st.pyplot(fig)
                
                with col2:
                    # Confidence distribution
                    fig, ax = plt.subplots(figsize=(8, 8))
                    sns.histplot(results_df['Confidence'], bins=10, kde=True, ax=ax)
                    ax.set_xlabel('Confidence Score')
                    ax.set_ylabel('Number of Reviews')
                    ax.set_title('Confidence Distribution')
                    st.pyplot(fig)

# Model Performance page
elif selection == "Model Performance":
    st.header("‚öôÔ∏è Model Performance Metrics")
    
    st.markdown("""
    ### About the Model
    
    This application uses **DistilBERT**, a distilled version of BERT that retains 97% of BERT's performance with 40% fewer parameters.
    The model is fine-tuned specifically for sentiment analysis using the Stanford Sentiment Treebank (SST-2) dataset.
    
    #### Key Features:
    * Processes full text sequences rather than individual words
    * Understands context and negations
    * Captures subtle sentiment cues
    * Handles complex language patterns
    
    #### Advantages over Traditional Approaches:
    * **Higher Accuracy**: Typically achieves 90-95% accuracy on sentiment classification tasks
    * **Better Context Understanding**: Considers the relationship between words
    * **Less Feature Engineering**: Does not require manual feature creation
    * **Language Understanding**: Trained on a diverse corpus of text
    """)
    
    # Compare to traditional models
    st.markdown("### Performance Comparison")
    
    comparison_data = pd.DataFrame({
        'Model': ['TF-IDF + Logistic Regression', 'BERT-based Model (Current)'],
        'Accuracy': [0.78, 0.92],
        'F1 Score': [0.76, 0.93],
        'Training Time': ['Fast', 'Slow (pre-trained)'],
        'Prediction Time': ['Very Fast', 'Fast'],
        'Context Understanding': ['Limited', 'Advanced'],
    })
    
    st.table(comparison_data)
    
    # Performance on challenging examples
    st.markdown("### Performance on Challenging Examples")
    
    challenging_examples = pd.DataFrame({
        'Review': [
            "The food wasn't bad, but I wouldn't say it was good either.",
            "This place used to be my favorite restaurant, but the quality has declined significantly.",
            "I was absolutely disappointed by how amazingly good the food was, totally didn't expect it!",
            "The meal was cold, but the service was outstanding."
        ]
    })
    
    if st.button("Analyze Challenging Examples"):
        with st.spinner("Analyzing challenging examples..."):
            results = []
            
            for review in challenging_examples['Review']:
                probs = predict_sentiment(review, st.session_state.tokenizer, st.session_state.model)
                sentiment = "Positive" if probs[1] >= 0.5 else "Negative"
                confidence = probs[1] if sentiment == "Positive" else probs[0]
                
                results.append({
                    'Review': review,
                    'Predicted_Sentiment': sentiment,
                    'Confidence': confidence,
                })
            
            challenging_results = pd.DataFrame(results)
            
            for i, row in challenging_results.iterrows():
                if row['Predicted_Sentiment'] == 'Positive':
                    st.markdown(f"""
                    <div class="sentiment-positive">
                        <h4>Example {i+1}: üòÉ Positive ({row['Confidence']:.2%} confidence)</h4>
                        <p>"{highlight_sentiment_words(row['Review'])}"</p>
                    </div>
                    <br>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class="sentiment-negative">
                        <h4>Example {i+1}: üòû Negative ({row['Confidence']:.2%} confidence)</h4>
                        <p>"{highlight_sentiment_words(row['Review'])}"</p>
                    </div>
                    <br>
                    """, unsafe_allow_html=True)
    
    # Technical details
    with st.expander("Technical Model Details"):
        st.markdown("""
        ### Model Architecture
        
        **DistilBERT Base Uncased (Fine-tuned for Sentiment)**
        * 6 layers, 768 hidden dimensions, 12 attention heads
        * 66M parameters (compared to BERT's 110M)
        * Self-attention mechanism for context understanding
        * Fine-tuned on Stanford Sentiment Treebank dataset
        
        ### Input Processing
        * Tokenization using WordPiece
        * Maximum sequence length: 512 tokens
        * Special tokens: [CLS] (classification) and [SEP] (separator)
        
        ### Output
        * Binary classification: Positive vs. Negative
        * Softmax probabilities for both classes
        """)

# Insights page
elif selection == "Insights":
    st.header("üí° Business Insights from Sentiment Analysis")
    
    if st.session_state.batch_results is not None:
        results_df = st.session_state.batch_results
        
        # Display overall sentiment distribution
        positive_percentage = (results_df['Predicted_Sentiment'] == 'Positive').mean() * 100
        
        # Create metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric(label="Positive Sentiment", value=f"{positive_percentage:.1f}%")
        with col2:
            avg_confidence = results_df['Confidence'].mean() * 100
            st.metric(label="Average Confidence", value=f"{avg_confidence:.1f}%")
        with col3:
            review_count = len(results_df)
            st.metric(label="Total Reviews", value=review_count)
        
        # Key word analysis
        st.subheader("Key Phrases Analysis")
        
        # Function to extract key phrases
        def extract_key_phrases(reviews, sentiment):
            stopwords_list = set(stopwords.words('english'))
            words = []
            
            for review in reviews:
                if isinstance(review, str):
                    # Clean and tokenize
                    clean_review = re.sub(r'[^\w\s]', '', review.lower())
                    review_words = clean_review.split()
                    
                    # Extract word pairs (bigrams)
                    if len(review_words) > 1:
                        for i in range(len(review_words) - 1):
                            if review_words[i] not in stopwords_list and review_words[i+1] not in stopwords_list:
                                words.append(f"{review_words[i]} {review_words[i+1]}")
            
            # Count word frequencies
            word_counts = pd.Series(words).value_counts().head(15)
            return word_counts
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Positive Review Key Phrases")
            positive_reviews = results_df[results_df['Predicted_Sentiment'] == 'Positive']['Review']
            positive_phrases = extract_key_phrases(positive_reviews, 'Positive')
            
            # Plot
            if not positive_phrases.empty:
                fig, ax = plt.subplots(figsize=(8, 10))
                bars = ax.barh(positive_phrases.index, positive_phrases.values, color='#99ff99')
                ax.set_xlabel('Frequency')
                ax.set_title('Common Phrases in Positive Reviews')
                ax.invert_yaxis()
                st.pyplot(fig)
            else:
                st.info("Not enough positive reviews to analyze phrases")
        
        with col2:
            st.markdown("#### Negative Review Key Phrases")
            negative_reviews = results_df[results_df['Predicted_Sentiment'] == 'Negative']['Review']
            negative_phrases = extract_key_phrases(negative_reviews, 'Negative')
            
            # Plot
            if not negative_phrases.empty:
                fig, ax = plt.subplots(figsize=(8, 10))
                bars = ax.barh(negative_phrases.index, negative_phrases.values, color='#ff9999')
                ax.set_xlabel('Frequency')
                ax.set_title('Common Phrases in Negative Reviews')
                ax.invert_yaxis()
                st.pyplot(fig)
            else:
                st.info("Not enough negative reviews to analyze phrases")
        
        # Business recommendations
        st.subheader("Business Recommendations")
        
        st.markdown("""
        ### Actionable Insights for Restaurant Owners
        
        Based on sentiment analysis of customer reviews, here are key actions restaurants can take:
        
        1. **Monitor Sentiment Trends Over Time**
           - Track how sentiment changes after menu updates or staff training
           - Identify seasonal patterns in customer satisfaction
        
        2. **Identify Specific Improvement Areas**
           - Analyze negative reviews for common complaints
           - Target staff training to address recurring issues
        
        3. **Leverage Positive Feedback**
           - Identify your restaurant's strengths from positive reviews
           - Highlight these strengths in marketing materials
        
        4. **Competitive Analysis**
           - Compare your sentiment scores with competitors
           - Identify areas where you outperform or underperform
        
        5. **ROI Measurement for Improvements**
           - Implement changes based on feedback
           - Measure sentiment before and after to quantify impact
        """)
        
        # Sample dashboard
        st.subheader("Sample Sentiment Dashboard")
        
        # Create some sample time-series data
        dates = pd.date_range(start='1/1/2023', periods=12, freq='M')
        sentiment_over_time = pd.DataFrame({
            'Date': dates,
            'Positive_Rate': [65, 68, 72, 75, 73, 78, 80, 82, 79, 83, 85, 88]
        })
        
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(sentiment_over_time['Date'], sentiment_over_time['Positive_Rate'], marker='o', linestyle='-', color='green')
        ax.set_xlabel('Date')
        ax.set_ylabel('Positive Reviews (%)')
        ax.set_title('Sentiment Trend Over Time')
        ax.grid(True, linestyle='--', alpha=0.7)
        
        # Add events
        events = {
            '2023-03-01': 'Menu Update',
            '2023-06-01': 'Staff Training',
            '2023-09-01': 'New Chef',
            '2023-12-01': 'Renovation'
        }
        
        for date_str, event in events.items():
            date = pd.to_datetime(date_str)
            idx = sentiment_over_time[sentiment_over_time['Date'] == date].index
            if len(idx) > 0:
                idx = idx[0]
                ax.annotate(event, 
                           (sentiment_over_time['Date'][idx], sentiment_over_time['Positive_Rate'][idx]),
                           xytext=(10, 10),
                           textcoords='offset points',
                           arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'))
        
        plt.tight_layout()
        st.pyplot(fig)
        
    else:
        st.info("Please run a batch analysis first to see insights. Go to the 'Batch Analysis' page and analyze some reviews.")
        
        if st.button("Use Sample Data For Insights"):
            # Generate sample results
            data = get_sample_data()
            
            results = []
            for review in data['Review']:
                probs = predict_sentiment(review, st.session_state.tokenizer, st.session_state.model)
                sentiment = "Positive" if probs[1] >= 0.5 else "Negative"
                confidence = max(probs)
                results.append({
                    'Review': review,
                    'Predicted_Sentiment': sentiment,
                    'Confidence': confidence,
                    'Positive_Probability': probs[1],
                    'Negative_Probability': probs[0]
                })
            
            # Store in session state
            st.session_state.batch_results = pd.DataFrame(results)
            
            # Refresh page
            st.experimental_rerun()

# Footer
st.markdown("""
---
### About This App
This app uses a state-of-the-art BERT-based deep learning model to analyze restaurant reviews.
It provides significantly higher accuracy than traditional machine learning approaches.
""")
